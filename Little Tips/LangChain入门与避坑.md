# LangChain å…¥é—¨ä¸é¿å‘æŒ‡åŒ—

> å‰è¨€ï¼š
>
> æœ¬æ–‡å¯¹æœ€è¿‘å­¦ä¹  LangChain çš„è¿‡ç¨‹è¿›è¡Œä¸€ä¸ªç®€å•çš„æ¦‚è¿°ï¼Œä»‹ç»åŸºæœ¬çš„æ¦‚å¿µã€ç®€è¿°éœ€è¦æ³¨æ„çš„é—®é¢˜ï¼Œå¹¶æä¾›æˆ‘è§‰å¾—å½“ä¸‹è¿˜ä¸é”™çš„å­¦ä¹ æ–¹æ³•ã€‚



## 1 å‰æœŸå‡†å¤‡

- Python åŸºç¡€ï¼Œa little å°±è¡Œï¼Œæˆ–è€…æ‹¥æœ‰åŸºæœ¬çš„ debug èƒ½åŠ›å³å¯ä¸Šæ‰‹
- shell åŸºç¡€ï¼Œç¯å¢ƒé—®é¢˜æ˜¯æ‰€æœ‰é—®é¢˜ä¸­æœ€å¤´ç–¼çš„é—®é¢˜ï¼Œæœ‰ shell å‘½ä»¤çš„åŸºç¡€èƒ½å¿«é€Ÿå¤ç°ç¯å¢ƒå³å¯
- é¢å‘å¯¹è±¡æ€æƒ³ã€‚å¯æœ‰å¯æ— ï¼Œè¿™æ˜¯åé¢è‡ªå·±æŸ¥çœ‹å·¥ç¨‹ç»“æ„çš„å¿…é¡»ï¼Œå‡å°‘é‡å¤ç¼–ç¨‹ã€‚
- 6g+ çš„æ˜¾å­˜ or OPENAI_API_KEYï¼Œæ˜¾å¡è¦æ±‚å…¶å®ä¸å¤§ï¼Œä»¥ ChatGLM-6B ä¸ºä¾‹ï¼Œ6g æ˜¾å­˜è·‘æ¨¡å‹æ²¡æœ‰é—®é¢˜ï¼Œä½†æ˜¯æˆ‘åœ¨å®è·µä¸­å‡ºç°äº†åˆšå¥½åƒæ»¡ 6gï¼Œå¯¼è‡´å†™çš„ langchain æäº¤ä¸ä¸Šå»çš„æƒ…å†µï¼Œå»ºè®®ä½¿ç”¨ 6g+ çš„æ˜¾å­˜ã€‚å¯¹æ˜¾å¡æ²¡è¦æ±‚~æ¯•ç«Ÿè·‘ 1 åˆ†é’Ÿå’Œè·‘ 5 åˆ†é’ŸåŒºåˆ«ä¸å¤§ã€‚
  OPENAI_API_KEY ä¸éœ€è¦ä¹° GPT 4.0 çš„ï¼ŒGPT 3.5 çš„å®Œå…¨å¤Ÿç”¨äº†ï¼Œåé¢ä¼šè¯¦ç»†è®²é…ç½®é—®é¢˜ã€‚KEY ä¹Ÿä¸è´µï¼Œè¶…è¿‡ 5 å—é’±å…ˆæ–Ÿé…Œä¸‹ï¼Œæˆ‘ä¹°çš„æ—¶å€™åªèŠ±äº† 3.2 å“¦~

------



## 2 é¿å‘æŒ‡åŒ—

ä¸‹é¢æ˜¯åœ¨å¼€å§‹å‰å…ˆç»™å¤§å®¶æè¿°ä¸‹æˆ‘é‡åˆ°çš„ä¸€äº›é”™è¯¯ï¼Œä»¥é˜²å¼€å§‹å­¦ä¹ ä¹‹åæŠ¥é”™æ‰¾äº†ä¸€åœˆå‘ç°å°±åœ¨è¯¥æ–‡æ¡£ä¸‹é¢ emmmmã€‚

#### ï¼ˆ1ï¼‰ç¯å¢ƒé—®é¢˜

å»ºè®®ä½¿ç”¨ conda å¯¹ç¯å¢ƒè¿›è¡Œç®¡ç†ï¼Œå¦‚æœä½ æƒ³ç”¨æœ¬åœ°æ˜¾å­˜è·‘æ¨¡å‹ï¼Œå¼ºçƒˆå»ºè®®**æ¨¡å‹å’Œ langchain ä½¿ç”¨ä¸¤å¥—ç¯å¢ƒï¼ï¼ï¼**ä»¥é˜²æ­¢ä¸­é€”å› ä¸ºä¸€äº›å¿…è¦æ’ä»¶å…³è”å¯¼è‡´çš„ç‰ˆæœ¬å˜åŠ¨ï¼Œä»¥è‡³äºç¨‹åºæ— æ³•å¯åŠ¨ã€‚

- **torch && torchvision**ï¼ˆæ®è¯´æœ‰80%çš„å°ç¬¨è›‹åœ¨å¼€å§‹å°±æ ½åœ¨äº†ç‰ˆæœ¬ä¸Šï¼Œç„¶å~å°±æ²¡æœ‰ç„¶åäº†ï¼‰

```python
# å¦‚æœä¸æ¸…æ¥šè‡ªå·±çš„ç‰ˆæœ¬çš„ï¼Œå¯ä»¥ä½¿ç”¨å¦‚ä¸‹ä»£ç è¿›è¡Œç¡®è®¤ï¼š
import torch
print(torch.__version__)
import torchvision
print(torchvision.__version__)

# æˆ‘ä½¿ç”¨çš„ç‰ˆæœ¬å¦‚ä¸‹ï¼š
# torch 1.13.1+cu117
# torchvision 0.14.1+cu117

# ç‰ˆæœ¬åŸºæœ¬æ²¡æœ‰ä¼˜åŠ£ä¹‹åˆ†ï¼ˆå› ä¸ºæˆ‘ä¹Ÿä¸æ¸…æ¥šï¼‰
# åœ¨åšå®¢ https://blog.csdn.net/shiwanghualuo/article/details/122860521 å¯ä»¥çœ‹åˆ°å¯¹ç…§
# ä¹Ÿå¯ä»¥ç›´æ¥è®¿é—®ï¼š
# https://gitcode.com/pytorch/vision?utm_source=csdn_github_accelerator&isLogin=1

# å®‰è£…ç‰ˆæœ¬å‘½ä»¤ emmmï¼Œä¸æ•™äº†ï¼Œä¸ä¼šæˆ‘è§‰å¾—å¯èƒ½ä½ ä¸é€‚åˆå­¦è¿™ä¸ª
```

- langchain ç¯å¢ƒä½¿ç”¨ä¸»è¦åŒ…ä½“å¦‚ä¸‹ï¼š

```requirement.txt
chromadb         # å­˜å‚¨å’ŒæŸ¥è¯¢ç¨‹å¼è¯­è¨€ç‰‡æ®µçš„æ•°æ®åº“
langchain[all]
# å¦‚æœæŠ¥é”™éœ€è¦ç»§ç»­è¡¥é½ langchain_community langchain_openaiç­‰ï¼ŒæŒ‰æŠ¥é”™ä¿¡æ¯æ¥
fastapi          # web api å·¥å…·
gradio           # å°†æ¨¡å‹ã€æ•°æ®é›†ã€æ–‡æœ¬ã€å›¾åƒç­‰å†…å®¹éƒ¨ç½²æˆç®€å•çš„ç•Œé¢
openai
pydantic         # æ•°æ®éªŒè¯å’Œè®¾ç½®åº“
pypdf            # å¤„ç† PDF æ–‡ä»¶çš„åº“
transformers     # Hugging Face å¼€å‘çš„è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡çš„åº“
unstructured     # å¤„ç†éç»“æ„åŒ–æ•°æ®
uvicorn          # å¿«é€Ÿçš„ ASGI æœåŠ¡å™¨
```

- æ¨¡å‹ç¯å¢ƒå°½é‡ä¸è¦å›¾æ–¹ä¾¿ä½¿ç”¨äººå®¶è‡ªå¸¦çš„ pythonï¼Œä¸æ˜¯å¾ˆå¥½ç®¡ç†ï¼Œnew ä¸€ä¸ªç¯å¢ƒç„¶åè¯»å– requirement.txtå³å¯ï¼Œä»¥ chatglm3 ä¸ºä¾‹ï¼Œä»–çš„æ–‡ä»¶å¦‚ä¸‹ï¼š

```requirement.txt
# basic requirements

protobuf>=4.25.2
transformers>=4.37.1
tokenizers>=0.15.0
cpm_kernels>=1.0.11
torch>=2.1.0
gradio>=4.16.0
sentencepiece>=0.1.99
sentence_transformers>=2.2.2
accelerate>=0.26.1
streamlit>=1.30.0
fastapi>=0.109.0
loguru~=0.7.2
mdtex2html>=1.3.0
latex2mathml>=3.77.0

# for openai demo

openai>=1.10.0
zhipuai>=2.0.1

pydantic>=2.5.3
sse-starlette>=2.0.0
uvicorn>=0.27.0
timm>=0.9.12
tiktoken>=0.5.2

# for langchain demo

langchain>=0.1.4
langchainhub>=0.1.14
arxiv>=2.1.0
```

**æ³¨æ„ï¼š**å¦‚æœå’Œæœ¬æ–‡å‘å¸ƒæ—¶é—´å¾ˆè¿‘çš„è¯ä¸å»ºè®®ä½¿ç”¨ GLM3 ä½œä¸ºæœ¬åœ°æ¨¡å‹ï¼Œç›®å‰ LangChain è¿˜æ²¡æœ‰å°† GLM3 çš„æ¥å£æ”¾å…¥ï¼Œéœ€è¦è‡ªå·±ç¼–å†™ã€‚ï¼ˆä¸è¿‡èƒ½è®©ä½ å¿«é€Ÿäº†è§£æºç ï¼‰



#### ï¼ˆ2ï¼‰LangChain é—®é¢˜

æ–°æŠ€æœ¯çš„åˆ°æ¥æ€»æ˜¯è®©äººå…´å¥‹çš„ï¼Œlangchain åœ¨æœ€è¿‘è¿æ¥äº†å®ƒçš„ 0.1.0 ç‰ˆæœ¬ã€‚mdå­¦èµ·æ¥è´¼è¾›è‹¦å¥½å§~æ”¾ä¸¤å¼ ä»Šå¤©å†™æ–‡çš„æ—¶å€™çš„æˆªå›¾ï¼š

![](img/langchain/ç‰ˆæœ¬1.png)

![](img/langchain/ç‰ˆæœ¬2.png)

å“¥ä»¬æˆ‘å­¦çš„æ—¶å€™è¿˜åªæœ‰ 0.1.3 å‘¢è‰¹ã€‚

è¨€å½’æ­£ä¼ ï¼Œlangchain 0.0 ç³»åˆ—å’Œ 0.1 ç³»åˆ—æœ€å¤§çš„å·®åˆ«å°±æ˜¯ä»¥å¾€å¾ˆå¤šæ¥å£å› ä¸ºå®ƒçš„æ¨¡å—åŒ–è®¾è®¡è¿›è¡Œäº†è°ƒæ•´ã€‚åœ¨ä¸‹é¢è¿›è¡Œç®€å•çš„ä¸¾ä¾‹ï¼š

```python
# éƒ¨åˆ†åŒ…åç”± langchain ä¸‹æ”¾åˆ° langchain_community/langchain_openai
# ä¸‹é¢æ˜¯å¸¸è§çš„æœ€æ–°çš„å¼•ç”¨ï¼ˆå«å˜åŠ¨ï¼‰

from langchain_community.document_loaders import UnstructuredURLLoader
from langchain_openai import OpenAI
from langchain_openai import ChatOpenAI

# invoke(Any) ä»£æ›¿æ‰§è¡Œè¯­å¥
# åœ¨å®æ“ä¸­æœ‰ä¸¤ä¸ªåœ°æ–¹é‡åˆ°äº†è¿™ä¸ªé—®é¢˜ï¼š
# eg.1
openaichat = ChatOpenAI(model_name="gpt-3.5-turbo")
# åŸ res = openaichat(msg)
res = openaichat.invoke(msg)  # è¾“å‡ºå†…å®¹ä¸å½±å“

# eg.2
llm = OpenAI(max_tokens=1500)
chain = load_summarize_chain(llm, prompt=chinese_prompt)
# åŸ summary = chain.run(news)
summary = chain.invoke(news)  
# å®æµ‹ invoke è¿”å›å†…å®¹ä¼šåŒ…å«'output_text'ã€'input_text'ç­‰ï¼Œ'output_text'ä¸ºåŸ run è¿”å›å†…å®¹

# ä¼šä¸ä¼šå½±å“ä½¿ç”¨æˆ‘ç›®å‰æ— æ³•ä¸‹å®šè®ºï¼Œå› ä¸ºæˆ‘æ‰€å¤„ç‰©ç†ç¯å¢ƒé—®é¢˜å¯å˜å‚æ•°å¤ªå¤šäº†ï¼Œ
# ä½†æ˜¯å»ºè®®å¤§å®¶ä¾æ®æ–°çš„è§„èŒƒæ¥å†™ï¼Œå› ä¸ºæ§åˆ¶å°åœ¨æ‰§è¡Œçš„æ—¶å€™ä¼šæŠ¥ warningï¼Œä¸”æ ¼å¼çœŸçš„å¾ˆä¸‘
# æœ‰å› ä¸ºä¸ä» langchain_openai å¼•å…¥å¯¼è‡´ç¨‹åºæ‰§è¡Œä¸ä¸‹å»çš„ç»å†ï¼Œä½†å°šä¸ç¡®è®¤æ˜¯å¦ä¸ºç½‘ç»œé—®é¢˜
```

###### å¦‚ä½•è§£å†³ langchain é—®é¢˜ï¼Ÿ

ç›®å‰æ¥çœ‹åº”è¯¥è¿˜æ²¡æœ‰å¾ˆå¥½ä¸”ç›´è§‚çš„é€”å¾„å»æŸ¥çœ‹æ–‡æ¡£ï¼Œè‹±æ–‡ã€ä¸­æ–‡æ–‡æ¡£çš„æ›´æ–°éƒ½æœ‰ä¸€å®šçš„æ»åæ€§ã€‚

å…¥é—¨äº†è§£æ¶æ„çš„è¯æ¨èä¸­æ–‡æ–‡æ¡£ï¼š[LangChainä¸­æ–‡ç½‘](https://www.langchain.com.cn/)

è‹±æ–‡æ–‡æ¡£ä¼šç¨å¾®å¿«ä¸€ç‚¹ï¼š[Introduction | ğŸ¦œï¸ğŸ”— Langchain](https://python.langchain.com/docs/get_started/introduction)

è§£å†³é—®é¢˜ç›´æ¥ github issue åŒºï¼ŒåŸºæœ¬ä¸ŠèŒæ–°å¼€å‘è€…é‡åˆ°çš„é—®é¢˜ CSDN å¯èƒ½è¿˜æ²¡åŒæ­¥ä½†æ˜¯ issue åŒºå·²ç»æœ‰äº†ï¼š[Issues Â· langchain-ai/langchain (github.com)](https://github.com/langchain-ai/langchain/issues) ç¤¾åŒºæ¯”è¾ƒæ´»è·ƒï¼Œå®åœ¨æ²¡æœ‰å°±æé—®å§ã€‚

------



## 3 LangChain å¾ˆæ‰¯æ·¡çš„å…¥é—¨ä»‹ç»

#### ï¼ˆ1ï¼‰å…³äº LangChain

ä¸ºä»€ä¹ˆè¦å« langchain å‘¢ï¼Ÿæ‹†å¼€æ¥å°±æ˜¯ lang & chainï¼Œlang çš„è¯å¦‚æœåœ¨ä¹‹å‰ä½ æ¥è§¦è¿‡ SpringBoot ä¹‹ç±»çš„é¡¹ç›®ï¼Œå¾ˆå¤šåç«¯ä¼šæŠŠä¸€äº›å›½é™…åŒ–ã€è¯­è¨€åŒ–çš„ä¸œè¥¿æ”¾åœ¨ä¸€ä¸ª lang æ–‡ä»¶å¤¹ä¸‹ï¼›è€Œ chain çš„è¯åˆ™æ›´å¥½ç†è§£ï¼Œlangchain æœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªä¸­é—´ä»¶ï¼Œç±»ä¼¼äºä½ å’Œæ•°æ®åº“äº¤äº’éœ€è¦ç”¨åˆ°çš„æ— è®ºæ˜¯ Mybatisã€Navicat ç­‰ç¨‹åºï¼Œlangchain æ˜¯æ–¹ä¾¿ä½ å’Œ LLM å¤§æ¨¡å‹äº¤äº’çš„å·¥å…·ã€‚

æ‰€ä»¥æˆ‘ä»¬æœ‰ç†ç”±çŒœæµ‹ï¼Œå¦‚åŒç°åœ¨å–œæ¬¢å°† datax ç­‰ç»„ä»¶å°è£…ä¸€å±‚ä½œä¸ºä¸­å°è‡ªåŠ¨åŒ–ä¸­é—´å±‚ï¼Œå‡ä½¿ langchain ä¿æŒå¦‚ä»Šçš„çƒ­åº¦ç»§ç»­å‘å±•ï¼Œä¹‹åä¹Ÿä¼šå˜æˆä¸€ä¸ªå¼€ç®±å³ç”¨çš„ UI ç»„ä»¶ã€‚

#### ï¼ˆ2ï¼‰LangChain çš„ä¸»è¦å·¥ä½œ

æ´å¼•è‡ª B ç«™è§†é¢‘ [ä¹å¤©ç©è½¬Langchain](https://www.bilibili.com/video/BV1E94y187YX?vd_source=75fc8fb6d21bda88e7f19b3fe3d00dbb)

LangChain ä½ çœ‹ä¸‹é¢æœ‰ 6 å¤§æ¨¡å—æ€ä¹ˆæ€ä¹ˆæ ·ï¼Œå…¶å®ä¹Ÿå°±é‚£æ · emmmï¼Œææ¸…æ¥šæµç¨‹æœºåˆ¶ä»¥åŠä½ å¯ä»¥åœ¨ä»€ä¹ˆåœ°æ–¹ä½¿ç”¨ï¼Œå·¥å…·å°±æ˜¯è¦ç”¨çš„æ—¶å€™å†çœ‹è¯´æ˜ä¹¦ã€‚

![](img/langchain/æµç¨‹å›¾.png)

æˆ‘è®¤ä¸º longchain ä¸»è¦åšçš„å°±æ˜¯ ETL å·¥ä½œï¼Œè®ºç‚¹å¦‚ä¸‹ï¼šçœ‹è§ä¸Šå›¾çš„ langchain çš„ä¸»è¦å·¥ä½œäº†å—ï¼Ÿä»æ•°æ®æºæŠ½å–ã€è½¬æ¢ã€åŠ è½½ï¼Œå¦¥å¦¥çš„ ETLã€‚å½“ç„¶ï¼Œæ·±å…¥çš„è¯´ï¼Œlangchain ä¸»è¦ç”¨æ¥å¯¹éç»“æ„åŒ–æ•°æ®ä¹Ÿå°±æ˜¯è¯­è¨€ã€æ–‡æœ¬ç­‰æœ‰å¾ˆå¥½çš„æ”¯æŒï¼Œå®ƒçš„è½¬æ¢ä¹Ÿä¸ä»…ä»…æ˜¯å¸¸è§„çš„æ ¼å¼è½¬æ¢ï¼Œè€Œæ˜¯å¯¹è¾“å…¥çš„é‡åŒ–ã€‚ï¼ˆä¸šå†…äººå£«å–œæ¬¢ç§°å…¶ä¸ºæ–‡æœ¬è¯åµŒå…¥ï¼ˆWord Embeddingï¼‰ï¼Œè¿™ä¸ªç¨åå†è¯´ï¼‰

store è¿‡ç¨‹åˆ™æ˜¯å°†æ•°æ®å†™åº“ï¼Œä½¿ç”¨ chromadbï¼Œè¿™æ˜¯ä¸ªè½»é‡çº§ä¸”å¯¹æ–‡æœ¬å‘é‡æ”¯æŒå‹å¥½çš„æ•°æ®åº“è½¬æ¢å™¨ï¼Œretrieve åˆ™æ˜¯å¯¹ store ä¸­çš„å†…å®¹è¿›è¡Œä¸€ä¸ªæç‚¼è¾“å‡ºã€‚

ä¸€å¥è¯æ¦‚æ‹¬å°±æ˜¯ï¼š**langchain å®Œæˆäº†å¯¹æ•°æ®ä¸€ä¸ªæç‚¼ã€æŸ¥æ‰¾çš„å®Œå…¨é“¾è·¯ã€‚**å®ƒå¹¶ä¸èƒ½æä¾›æ•°æ®æºã€æŸ¥æ‰¾ç†ç”±ï¼Œåªæ˜¯ä¸€ç§æ–¹æ³•çš„å‡ç»ƒã€‚

æ•°æ®æºæ”¯æŒç”±ç”¨æˆ·ç­‰è‡ªè¡Œæä¾›ï¼Œå› æ­¤å®ƒæ”¯æŒæœ¬åœ°çŸ¥è¯†åº“çš„æ­å»ºï¼Œåˆç†æƒ³è±¡æœªæ¥çš„å­¦ç”Ÿè¯¾è®¾ç³»ç»Ÿå°†ä¼šæ˜¯ï¼šé‡‘èçŸ¥è¯†ç³»ç»Ÿï¼ˆä½¿ç”¨ langchain çˆ¬å–é‡‘èç½‘ç«™æå–æ‘˜è¦å‡ç»ƒæˆçŸ¥è¯†ï¼‰ã€å›¾ä¹¦ç®€ä»‹ç³»ç»Ÿï¼ˆä½¿ç”¨ langchain å¯¹å›¾ä¹¦æå–æ‘˜è¦è¿›è¡Œå±•ç¤ºï¼‰â€¦â€¦

å…³äºæŸ¥æ‰¾ç†ç”±è¿™ä¸€æ®µæˆ‘æ˜¯æœ‰ç«¯è”æƒ³çš„ï¼Œå¹¶éè€ƒæ®ï¼šåœ¨å­¦ä¹ è§†é¢‘çš„è¿‡ç¨‹ä¸­å‘ç°ä½¿ç”¨ GLM-6B æœ¬åœ°è¿è¡Œå¯¹å°æ–‡æœ¬å¤„ç†æ€§èƒ½å¹¶ä¸ä¼˜ç§€ï¼Œä½†æ˜¯æ¢ä¸Š OPENAI_API_KEY ä¹‹åçš„æ•ˆæœå´è®©äººæ»¡æ„ã€‚æˆ‘è®¤ä¸ºæ˜¯æ¨¡å‹åœ¨è¾“å‡ºè¿‡ç¨‹ä¸­å æ®ä¸»å¯¼åœ°ä½ï¼Œä¸”è¶Šå¤§è®­ç»ƒçš„æ¨¡å‹å¤„ç†å°å¾®æ•°æ®çš„æ•ˆæœå¯èƒ½ä¼šæ›´å¥½ï¼ˆä½†ç›®å‰æˆ‘è¿˜æ²¡è¯»æºç ï¼‰ã€‚è€Œ langchain åœ¨è¿™è¿‡ç¨‹ä¸­ä¸»è¦è¿˜æ˜¯æ‰®æ¼”ä¸€ä¸ªåŠ©æ‰‹çš„èº«ä»½ï¼Œå¯¹è¾“å…¥è¿›è¡Œä¿®ä¿®è¡¥è¡¥ä»¥åŠå¯¹è¾“å‡ºè¿›è¡Œä¿®ä¿®è¡¥è¡¥ã€‚

#### ï¼ˆ3ï¼‰æ–‡æœ¬è¯åµŒå…¥ï¼ˆWord Embeddingï¼‰

è¿™é‡Œæˆ‘ç›´æ¥ä½¿ç”¨ä¸Šé¢è§†é¢‘ä¸­çš„ä¾‹å­è¿›è¡Œç®€å•ä»‹ç»ï¼Œè¯¦ç»†å¤§å®¶å¯ä»¥è‡ªå·±æ‰¾èµ„æ–™æˆ–è€…çœ‹è§†é¢‘~

```markdown
è¯åµŒå…¥æ˜¯è¯è¯­çš„ä¸€ç§æ•°å€¼åŒ–è¡¨ç¤ºæ–¹å¼ï¼Œä¸€èˆ¬æƒ…å†µä¸‹ä¼šå°†ä¸€ä¸ªè¯æ˜ å°„åˆ°ä¸€ä¸ªé«˜ç»´çš„å‘é‡ä¸­ï¼ˆè¯å‘é‡vectorï¼‰

- ä¾‹å­ï¼š
  - â€œæˆ‘â€ --> [0, 0.3, -0.1]
  - â€œä½ â€ --> [-0.6, 0.12, 0.16]
  - â€œä¿ºâ€ --> [0.01, 0.298, -0.99]

å‘é‡åŒ–çš„æ„ä¹‰ï¼š
å°†ä½ç»´çš„è¯/å¥å­è½¬æ¢ä¸ºé«˜ç»´çš„å‘é‡ï¼Œæ–¹ä¾¿è¿›è¡Œæ•°å­—åŒ–è¡¨è¾¾
æ¢è¨€ä¹‹ï¼šæ¥è¿‘çš„è¯­ä¹‰=æ¥è¿‘çš„é«˜ç»´è·ç¦»
```

B ç«™æœ‰å¾ˆå¤šä¸é”™çš„ embedding ä»‹ç»ï¼Œé™„ä¸Šæˆ‘å¾ˆå–œæ¬¢çš„ä¸€å¥è¯ï¼š**â€œä¸‡ç‰©çš†å¯ embeddingâ€**ï¼Œå¯è§ï¼Œembedä¸»è¦æ˜¯å¯¹éç»“æ„åŒ–æ•°æ®è¿›è¡Œçš„å‡ç»´æ“ä½œï¼Œå¯¹äº‹ç‰©å»ºç«‹èµ·å…³è”ã€‚

------



## 4 æ¨¡å—ç®€ä»‹

çœ‹åˆ°è¿™äº†ï¼Œæˆ‘è§‰å¾—ä½ å¯ä»¥åŠ¨æ‰‹å®è·µä¸‹äº†ï¼Œå…³äºæ¨¡å—çš„éƒ¨åˆ†æˆ‘è®¤ä¸ºäº²æ‰‹å®è·µä¸€æ¬¡ä¼šæ¯”å¹²å·´å·´çš„è®²è§£æœ‰æ•ˆå¾ˆå¤šï¼Œå¦‚æœä½ ä¹Ÿè®¤åŒæˆ‘è¯´çš„ï¼Œå¯ä»¥å»æˆ‘çš„å¦ä¸€ç¯‡æ–‡ç« ã€ŠLangChain å®è·µã€‹åšä¸€ä¸ªæœ¬åœ°çš„çŸ¥è¯†åº“é—®ç­”ï¼Œå¾ˆçŸ­çš„ä»£ç å´èƒ½è®©ä½ æœ‰å…¨æ–°çš„ä½“æ‚Ÿï¼Œæˆ–è€…è·Ÿç€ä¸‹é¢çš„å‡ ä¸ªæ¨¡å—ï¼Œæˆ‘ç²—ç•¥çš„è®²è§£ã€‚

æˆ‘å¹¶ä¸å‡†å¤‡æŒ‰ç…§å®˜æ–¹é¡ºåºæˆ–è€…è¯‘æ–‡é¡ºåºæ¥ä»‹ç»æ¨¡å—ï¼Œè¯´å®è¯æ—¢ç„¶æœ‰å®˜æ–¹æ–‡æ¡£é‚£ä¹ˆå¾ˆå¤šä¸œè¥¿å…¶å®åº”è¯¥ä¾§é‡äºä»¥å·¥ç¨‹çš„è§’åº¦å»ç§‘æ™®ä»‹ç»ï¼Œè€Œéæ¶¦è‰²ä¸‹è¯‘æ–‡ç›´æ¥ç…§æ¬ï¼ˆå¦‚æ­¤æˆ‘å»ºè®®å¯ä»¥å»è¯‘æ–‡çš„ github æ prï¼‰

#### ï¼ˆ0ï¼‰Transformers ä¹±å…¥

æˆ‘ä»¬æœ€å…ˆæƒ³åˆ°ç”¨ langchain ä¸€å®šæ˜¯æˆ‘ä»¬éœ€è¦å’Œæ¨¡å‹è¿›è¡Œäº¤äº’äº†ï¼Œé‚£ä¹ˆæ¨¡å‹åœ¨å“ªæ¥ï¼Ÿæ¨¡å‹æ˜¯æ€ä¹ˆå¯åŠ¨çš„ï¼Ÿæ¨¡å‹çš„æ„æˆæ˜¯ä»€ä¹ˆï¼Ÿè¿™äº›~æˆ‘éƒ½è¿˜ä¸çŸ¥é“ emmmï¼Œä¹‹åä¼šæŠ½æ—¶é—´ç ”ç©¶ Transformers çš„æºç ï¼Œå†å†™ä¸ªã€Šåˆæ¢ Transformersã€‹çš„å…¥é—¨åæ§½ã€‚

è¨€å½’æ­£ä¼ ï¼Œæ¨¡å‹çš„å¯åŠ¨å¦‚ä¸‹ï¼š

```python
# å¯¼å…¥ AutoTokenizer å’Œ AutoModelï¼Œç”¨äºä»é¢„è®­ç»ƒæ¨¡å‹ä¸­åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨
from transformers import AutoTokenizer, AutoModel

# ä»æœ¬åœ°åŠ è½½ chatglm-6b é¢„è®­ç»ƒæ¨¡å‹çš„åˆ†è¯å™¨ï¼Œtrust_remote_code=True è¡¨ç¤ºä¿¡ä»»è¿œç¨‹ä»£ç 
tokenizer = AutoTokenizer.from_pretrained("./ChatGML/model/chatglm-6b", trust_remote_code=True)

# ä»æœ¬åœ°åŠ è½½ chatglm-6b é¢„è®­ç»ƒæ¨¡å‹ï¼Œtrust_remote_code=True è¡¨ç¤ºä¿¡ä»»è¿œç¨‹ä»£ç 
model = AutoModel.from_pretrained("./ChatGML/model/chatglm-6b", trust_remote_code=True).quantize(4).half().cuda()

# å°†æ¨¡å‹è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
model = model.eval()

# ä½¿ç”¨æ¨¡å‹è¿›è¡Œå¯¹è¯ï¼Œåˆå§‹å¯¹è¯å†…å®¹ä¸º "ä½ å¥½"ï¼Œhistory=[] è¡¨ç¤ºåˆå§‹å¯¹è¯å†å²ä¸ºç©º
response, history = model.chat(tokenizer, "ä½ å¥½", history=[])
# æ‰“å°æ¨¡å‹ç»™å‡ºçš„å›å¤
print(response)

# ä½¿ç”¨æ¨¡å‹è¿›è¡Œå¯¹è¯ï¼Œå¯¹è¯å†…å®¹ä¸º "æ™šä¸Šç¡ä¸ç€æ€ä¹ˆåŠ"ï¼Œä½¿ç”¨ä¹‹å‰çš„å¯¹è¯å†å²ä½œä¸ºä¸Šä¸‹æ–‡
response, history = model.chat(tokenizer, "æ™šä¸Šç¡ä¸ç€æ€ä¹ˆåŠ", history=history)
# æ‰“å°æ¨¡å‹ç»™å‡ºçš„å›å¤
print(response)

"""
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:22<00:00,  2.81s/it]
ä½ å¥½ğŸ‘‹!æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM-6B,å¾ˆé«˜å…´è§åˆ°ä½ ,æ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚
ä»¥ä¸‹æ—¶æ˜¯ä¸€äº›æœ‰ç”¨çš„æŠ€å·§,å¯ä»¥å¸®åŠ©åœ¨æ™šä¸Šå…¥ç¡:
1. ä¿æŒæ”¾æ¾:å°è¯•è¿›è¡Œæ·±å‘¼å¸ã€å†¥æƒ³æˆ–æ”¾æ¾ç»ƒä¹ ,å‡è½»å‹åŠ›å’Œç„¦è™‘ã€‚
2. åˆ›é€ èˆ’é€‚çš„ç¡çœ ç¯å¢ƒ:ç¡®ä¿å§å®¤å®‰é™ã€é»‘æš—ã€å‡‰çˆ½å’Œèˆ’é€‚,å¯èƒ½éœ€è¦ä½¿ç”¨è€³å¡ã€çœ¼ç½©ç­‰ã€‚
3. åˆ¶å®šè§„å¾‹çš„ç¡çœ æ—¶é—´è¡¨:æ¯å¤©åœ¨åŒä¸€æ—¶é—´ä¸ŠåºŠ,ä¿æŒç›¸åŒçš„èµ·åºŠæ—¶é—´,å¸®åŠ©èº«ä½“å»ºç«‹ä¸€ä¸ªæ­£å¸¸çš„ç¡çœ èŠ‚å¾‹ã€‚
4. é¿å…åˆºæ¿€:åœ¨ç¡è§‰å‰å‡ ä¸ªå°æ—¶å†…é¿å…é¥®ç”¨å’–å•¡å› ã€é…’ç²¾æˆ–å°¼å¤ä¸,å¹¶é¿å…åœ¨ç¡å‰è¿›è¡Œåˆºæ¿€æ€§çš„æ´»åŠ¨,å¦‚çœ‹ç”µè§†æˆ–ä½¿ç”¨ç”µè„‘ã€‚
5. æš´éœ²äºå…‰çº¿ä¸‹:åœ¨ç¡è§‰å‰å‡ ä¸ªå°æ—¶å†…,å°†æ‰‹æœºæˆ–ç”µè„‘å±å¹•è°ƒæš—,å¹¶å°½å¯èƒ½è®©å…‰çº¿æš´éœ²äºå®¤å¤–,å¦‚é˜³å…‰æˆ–æˆ·å¤–å¤œæ™¯,å¸®åŠ©èº«ä½“æš´éœ²äºå…‰çº¿ä¸‹,æé«˜å…¥ç¡æ‰€éœ€çš„å…‰çº¿æ°´å¹³ã€‚
6. å°è¯•è¿›è¡Œå†¥æƒ³æˆ–æ·±åº¦å‘¼å¸ç»ƒä¹ :è¿™äº›æŠ€å·§å¯ä»¥å¸®åŠ©æ”¾æ¾èº«ä½“å’Œæ€ç»´,æé«˜å…¥ç¡çš„èƒ½åŠ›ã€‚
å¦‚æœè¿™äº›æ–¹æ³•ä¸èµ·ä½œç”¨,ä¹Ÿå¯ä»¥å°è¯•å’¨è¯¢åŒ»ç”Ÿæˆ–ç¡çœ ä¸“å®¶,è·å–æ›´å…·ä½“çš„å»ºè®®å’Œå¸®åŠ©ã€‚
è¿›ç¨‹å·²ç»“æŸ,é€€å‡ºä»£ç 0
"""
```

è¿™å°±æ˜¯ä¸€ä¸ªåŸºæœ¬çš„æ¨¡å‹åŠ è½½å¯åŠ¨å¹¶é—®ç­”çš„æµç¨‹ã€‚è¯¦ç»†å‚æ•°çš„ç¤ºæ„å¦‚ä¸‹ï¼ˆç”± GPT æä¾›ï¼‰ï¼š

åœ¨æ·±åº¦å­¦ä¹ æ¡†æ¶ä¸­ï¼Œ`model.eval()` çš„ä½œç”¨æ˜¯å°†æ¨¡å‹è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ã€‚åœ¨è¯„ä¼°æ¨¡å¼ä¸‹ï¼Œæ¨¡å‹é€šå¸¸ä¼šå…³é—­ä¸€äº›è®­ç»ƒä¸­ä¼šç”¨åˆ°ä½†åœ¨è¯„ä¼°æ—¶ä¸éœ€è¦çš„åŠŸèƒ½ï¼Œæ¯”å¦‚ dropout å’Œ batch normalization çš„è®¡ç®—ï¼Œè¿™æœ‰åŠ©äºæé«˜è¯„ä¼°æ—¶çš„è®¡ç®—æ•ˆç‡ã€‚æ­¤å¤–ï¼Œ`model.eval()` è¿˜ä¼šå½±å“æŸäº›æ¨¡å‹ï¼Œæ¯”å¦‚åœ¨ä½¿ç”¨ PyTorch æ¡†æ¶æ—¶ï¼Œä¼šå½±å“ BatchNorm å’Œ Dropout å±‚ç­‰ã€‚

å¯¹äº `.quantize(4).half().cuda()` è¿™ä¸€æ–¹æ³•é“¾ï¼Œå®ƒåŒ…å«äº†ä»¥ä¸‹å‡ ä¸ªæ“ä½œï¼š

- `quantize(4)`ï¼šè¿™ä¸€æ“ä½œæ˜¯å¯¹æ¨¡å‹è¿›è¡Œé‡åŒ–ï¼ˆQuantizationï¼‰ï¼Œå°†æ¨¡å‹ä¸­çš„å‚æ•°ä»æµ®ç‚¹æ•°æ ¼å¼è½¬æ¢ä¸ºå®šç‚¹æ•°æ ¼å¼ã€‚æ‹¬å·ä¸­çš„å‚æ•° 4 è¡¨ç¤ºå°†å‚æ•°é‡åŒ–ä¸º 4 ä½ï¼Œä»è€Œå‡å°‘æ¨¡å‹çš„å­˜å‚¨ç©ºé—´å’Œè®¡ç®—é‡ã€‚é‡åŒ–é€šå¸¸ç”¨äºä¼˜åŒ–æ¨¡å‹çš„æ¨ç†æ•ˆç‡ã€‚
- `half()`ï¼šè¿™ä¸€æ“ä½œå°†æ¨¡å‹ä¸­çš„æ•°æ®ç±»å‹ä» 32 ä½æµ®ç‚¹æ•°ï¼ˆfloat32ï¼‰è½¬æ¢ä¸º 16 ä½æµ®ç‚¹æ•°ï¼ˆfloat16ï¼‰ï¼Œè¿™ç§æ“ä½œè¢«ç§°ä¸ºåŠç²¾åº¦æµ®ç‚¹æ•°è®¡ç®—ã€‚è¿™æ ·åšå¯ä»¥æ˜¾è‘—å‡å°‘æ¨¡å‹åœ¨ GPU ä¸Šçš„å†…å­˜å ç”¨ï¼Œå¹¶æé«˜è®¡ç®—é€Ÿåº¦ã€‚
- `cuda()`ï¼šè¿™ä¸€æ“ä½œå°†æ¨¡å‹è½¬ç§»åˆ° GPU ä¸Šè¿›è¡Œè®¡ç®—ï¼Œå¦‚æœ GPU å¯ç”¨çš„è¯ã€‚è¿™æ ·å¯ä»¥åˆ©ç”¨ GPU çš„å¹¶è¡Œè®¡ç®—èƒ½åŠ›æ¥åŠ é€Ÿæ¨¡å‹çš„æ¨ç†è¿‡ç¨‹ã€‚

å¦‚ä¸Šæ‰€è§ï¼ŒHF çš„ Transformers æä¾›äº†ä¾¿æ·çš„æ–¹å¼å¯åŠ¨æ¨¡å‹ï¼Œä½†æ˜¯ langchain å¹¶éæŠ¢äº† transformers çš„æ´»ï¼Œè€Œæ˜¯å¾ˆå¥½çš„å¯¹æ¥äº† chat æ¥å£ï¼Œæä¾›æ›´é«˜æ•ˆå’Œä¾¿æ·çš„é¢„å¤„ç†æˆ–æ˜¯ä¼˜åŒ–æ–¹å¼ã€‚

ä¸‹é¢æ˜¯ ChatGLM3 çš„ api_server.py æ–‡ä»¶ä¸­çš„éƒ¨åˆ†ï¼Œæœ¬è´¨ä¸Šæ˜¯å¯åŠ¨æ¨¡å‹åå¼€æ”¾äº†ä¸€ä¸ªå¯è®¿é—®çš„æ¥å£ï¼š

```python
if __name__ == "__main__":
    # Load LLM
    tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH, trust_remote_code=True)
    model = AutoModel.from_pretrained(MODEL_PATH, trust_remote_code=True, device_map="auto").eval()

    # load Embedding
    embedding_model = SentenceTransformer(EMBEDDING_PATH, device="cuda")
    uvicorn.run(app, host='0.0.0.0', port=8000, workers=1)
```

é‚£ä¹ˆç°åœ¨æˆ‘ä»¬å°±èƒ½å¼€å§‹çœŸæ­£è¿›å…¥ langchainï¼Œçœ‹çœ‹ä»–å¯¹è¿™ä¸ªæ¥å£æä¾›äº†äº›ä»€ä¹ˆï¼Ÿåˆå¯¹è¿”å›è¿›è¡Œäº†ä»€ä¹ˆæ ·çš„å¤„ç†~

#### ï¼ˆ1ï¼‰æ¨¡å—ä¸€ï¼šæ¨¡å‹ Models

###### ã€1ã€‘åŠ è½½ LLM

å› ä¸ºç›®å‰ ChatGLM3 è¿˜æ¯”è¾ƒæ–°ï¼Œæˆ‘ä½¿ç”¨çš„ langchain ç‰ˆæœ¬è¿˜æœªæ›´æ–° 3 çš„æ¥å£ï¼Œæ‰€ä»¥æµ‹è¯•çš„æ—¶å€™æ˜¯ä½¿ç”¨çš„è‡ªå·±çš„ChatGLM3 ç±»~

```python
from langchain_chatglm3 import ChatGLM3
llm = ChatGLM3(endpoint_url="http://localhost:8000/")
response = llm.invoke('ä½ å¥½')
```

å½“ç„¶ï¼Œ`langchain_chatglm3` å¹¶ä¸æ˜¯å®˜æ–¹çš„ç±»ï¼Œè¿™é‡Œåªæ˜¯ä½¿ç”¨æœ¬åœ°ç®€å•æ–¹æ³•æ‰“ä¸ªæ ·ï¼Œåç»­çš„å¯åŠ¨å°†ä½¿ç”¨ `OPENAI_API_KEY ` çš„æ–¹å¼è¿›è¡Œã€‚

soï¼Œé¦–å…ˆéœ€è¦å°† `OPENAI_API_KEY ` å¯¼å…¥ç¯å¢ƒï¼Œä½ å¯ä»¥é€‰æ‹©ç›´æ¥å†™å…¥ç¯å¢ƒå˜é‡ï¼ŒæŠ‘æˆ–æ˜¯åœ¨é¡¹ç›®ä¸‹é…ç½® `.env` æ–‡ä»¶ï¼Œæˆ‘é‡‡ç”¨çš„æ˜¯æœ€è€åœŸçš„æ–¹å¼ï¼š

```python
import os
os.environ["OPENAI_API_BASE"] = 'https://~'  # æ¥å£ç½‘å€
os.environ["OPENAI_API_KEY"] = 'sk-~'  # Key å€¼
```

å†™å…¥åˆ°äº†ç¯å¢ƒä¹‹åè‡ªç„¶å°±ä¸éœ€è¦å¯åŠ¨æ¨¡å‹çš„æ—¶å€™é…ç½® endpoint_url äº†ï¼Œé‚£ä¹ˆä»£ç å¦‚ä¸‹ï¼š

```python
from langchain_openai import OpenAI
llm = OpenAI()
response = llm.invoke('ä½ å¥½')
```

é‚£ä¹ˆåˆ°è¿™é‡Œï¼Œå°±æ˜¯ Model æ¨¡å—çš„ä¸€åŠå†…å®¹äº†ï¼Œä½œä¸ºä¸€ä¸ªåˆå­¦è€…ï¼Œä½ ç°åœ¨åº”è¯¥æŒæ¡äº†ä½¿ç”¨ä¸€ä¸ªæ¨¡å‹ï¼Œå¹¶æ¥æ”¶è¿”å›çš„èƒ½åŠ›ï¼Œå…³äºå…¶ä»–ä»€ä¹ˆå¼‚æ­¥å•Šã€è‡ªå®šä¹‰å•Šï¼Œé‚£éœ€è¦åœ¨å·¥ç¨‹å®è·µä¸­æŒæ¡ï¼Œæœ‰éœ€æ±‚çœ‹æ–‡æ¡£å°±è¡Œã€‚

###### ã€2ã€‘æ–‡æœ¬åµŒå…¥ text embedding

> Embedding ç±»æ˜¯ä¸€ä¸ªç”¨äºä¸åµŒå…¥è¿›è¡Œäº¤äº’çš„ç±»ã€‚æœ‰è®¸å¤šåµŒå…¥æä¾›å•†ï¼ˆOpenAIã€Cohereã€Hugging Faceç­‰)ï¼Œè¿™ä¸ªç±»æ—¨åœ¨ä¸ºæ‰€æœ‰è¿™äº›æä¾›å•†æä¾›ä¸€ä¸ªæ ‡å‡†æ¥å£ã€‚
>
> åµŒå…¥ä¼šåˆ›å»ºæ–‡æœ¬çš„å‘é‡è¡¨ç¤ºã€‚è¿™å¾ˆæœ‰ç”¨ï¼Œå› ä¸ºè¿™æ„å‘³ç€æˆ‘ä»¬å¯ä»¥åœ¨å‘é‡ç©ºé—´ä¸­è€ƒè™‘æ–‡æœ¬ï¼Œå¹¶æ‰§è¡Œè¯¸å¦‚è¯­ä¹‰æœç´¢ä¹‹ç±»çš„æ“ä½œï¼Œå…¶ä¸­æˆ‘ä»¬åœ¨å‘é‡ç©ºé—´ä¸­å¯»æ‰¾æœ€ç›¸ä¼¼çš„æ–‡æœ¬ç‰‡æ®µã€‚
>
> LangChain ä¸­çš„åŸºæœ¬ Embedding ç±»å…¬å¼€äº†ä¸¤ç§æ–¹æ³•ï¼šembed_documents å’Œ embed_queryã€‚æœ€å¤§çš„åŒºåˆ«åœ¨äºè¿™ä¸¤ç§æ–¹æ³•å…·æœ‰ä¸åŒçš„æ¥å£ï¼šä¸€ä¸ªé€‚ç”¨äºå¤šä¸ªæ–‡æ¡£ï¼Œè€Œå¦ä¸€ä¸ªé€‚ç”¨äºå•ä¸ªæ–‡æ¡£ã€‚é™¤æ­¤ä¹‹å¤–ï¼Œå°†è¿™ä¸¤ä¸ªæ–¹æ³•ä½œä¸ºä¸¤ä¸ªå•ç‹¬çš„æ–¹æ³•çš„å¦ä¸€ä¸ªåŸå› æ˜¯ï¼ŒæŸäº›åµŒå…¥æä¾›å•†é’ˆå¯¹è¦æœç´¢çš„æ–‡æ¡£ä¸æŸ¥è¯¢æœ¬èº«å…·æœ‰ä¸åŒçš„åµŒå…¥æ–¹æ³•ã€‚
>
> â€”â€”æ‘˜è‡ª langchain ä¸­æ–‡ç½‘

è¿˜è®°å¾—å†™åœ¨å‰é¢çš„æ–‡æœ¬è¯åµŒå…¥å—ï¼Ÿç®€å•æ¥è¯´å°±æ˜¯å°†æ–‡å­—å‘é‡åŒ–ï¼Œè¿™å½“ç„¶ä¸æ˜¯ä¸€ä¸ªå‡½æ•°å°±èƒ½è§£å†³çš„é—®é¢˜ï¼Œå…·ä½“å®ç°åŸç†çš„è¯å¯èƒ½ emmm éœ€è¦å¼€ä¸ªå•ç« å»ç ”ç©¶ä¸‹æ¨¡å‹å®ç°ï¼Œç°åœ¨æˆ‘ä»¬åªéœ€è¦çŸ¥é“ï¼šæ‰§è¡Œçš„è¿‡ç¨‹å·²ç»å°è£…å¥½äº†ï¼Œå‘Šè¯‰ langchain ä½ é€‰æ‹©çš„ embedding æ¨¡å‹å³å¯ï¼Œæœ‰è¯· VCRï¼š

```python
from langchain.embeddings.huggingface import HuggingFaceEmbeddings
# ä¸€ä¸ª embedding åˆ—è¡¨ï¼Œè®°å½•å¸¸ç”¨çš„ embedding å¯¹ç…§å…³ç³»
embeddings_model_dict = {
    "ernie-tiny": "nghuyong/ernie-3.0-nano-zh",
    "ernie-base": "nghuyong/ernie-3.0-base-zh",
    "text2vec": "GranymeNil/text2vec-large-chinese",
    "text2vec2": "uer/sbert-base-chinese-nil",
    "text2vec3": "shibing624/text2vec-base-chinese",
}

def load_embedding_mode(model_name="ernie-tiny"):
    encode_kwargs = {"normalize_embeddings": False}
    model_kwargs = {"device": "cuda:0"}
    return HuggingFaceEmbeddings(
        model_name=embeddings_model_dict[model_name],
        encode_kwargs=encode_kwargs,
        model_kwargs=model_kwargs
    )

embeddings = load_embedding_mode('text2vec3')
print(embeddings)

"""
client=SentenceTransformer(
  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: BertModel 
  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False})
) model_name='shibing624/text2vec-base-chinese' cache_folder=None model_kwargs={'device': 'cuda:0'} encode_kwargs={'normalize_embeddings': False} multi_process=False
"""
```

å¯ä»¥çœ‹åˆ°ï¼šembedding è¿”å›çš„æ˜¯ä¸€å¤§å †å‚æ•°ï¼Œä¸€äº›å¯ä»¥è‡ªå®šä¹‰ï¼Œä¸€äº›ç”±æ¨¡å‹ç»™å‡ºã€‚çœ‹ä¸æ‡‚ä¹Ÿæ²¡å…³ç³»ï¼Œå®ƒç›¸å½“äºå®šä¹‰äº†æ–‡å­—å‘é‡åŒ–çš„æ¡†æ¶ï¼Œè¿™ä¸ºæˆ‘ä»¬ä¸‹ä¸€ä¸ªæ¨¡å—æ‰“ä¸‹äº†åŸºç¡€ã€‚



#### ï¼ˆ2ï¼‰æ¨¡å—äºŒï¼šç´¢å¼• Indexes

ä¹¦æ¥ä¸Šæ–‡ï¼Œæˆ‘æ‹¿åˆ°äº† embedding ç»™æˆ‘çš„è§„åˆ™å¦‚ä½•å°†æˆ‘è¦çš„å†…å®¹å‘é‡åŒ–å‘¢ï¼Ÿå‘é‡åŒ–ä¹‹åæˆ‘åˆè¯¥å¦‚ä½•ä½¿ç”¨å‘¢ï¼Ÿå› æ­¤ç¬¬äºŒæ­¥ï¼Œæˆ‘ä»¬å°±éœ€è¦å¯¹æ•°æ®è¿›è¡Œå¤„ç†~

ç´¢å¼•ä¸‹ä¸€å…±åˆ†ä¸ºå››ä¸ªéƒ¨åˆ†ï¼š

- æ–‡æ¡£åŠ è½½å™¨ï¼ˆDocument Loadersï¼‰
- æ–‡æœ¬åˆ†å‰²å™¨ï¼ˆText Splittersï¼‰

```python
from langchain_community.document_loaders import DirectoryLoader
from langchain.text_splitter import CharacterTextSplitter
# è¿™é‡Œå‚æ•°é»˜è®¤æ˜¯åŒçº§ç›®å½•ä¸‹ data æ–‡ä»¶å¤¹ä¸­çš„æ–‡ä»¶
def load_document(directory="data"):
    loader = DirectoryLoader(directory)
    documents = loader.load()
    # åˆå§‹åŒ–ï¼ŒæŒ‡å®šæ¯ä¸ªæ‹†åˆ†å—çš„å¤§å°å’Œå—ä¹‹é—´çš„é‡å é‡
    text_splitter = CharacterTextSplitter(chunk_size=256, chunk_overlap=0)
    split_docs = text_splitter.split_documents(documents)
    return split_docs

documents = load_document()
```

ç”±ä¸Šé¢çš„ä»£ç å¯è§ï¼Œéå¸¸çš„è§åçŸ¥æ„ï¼Œæœ€å¤šå°±æ˜¯åˆæœŸç…§ç€æ–‡æ¡£ç†Ÿæ‚‰ä¸‹æ¥å£~

- å‘é‡å­˜å‚¨ï¼ˆVectorstoresï¼‰

```python
from langchain_community.vectorstores import Chroma
# å°†å‘é‡æ•°æ®å†™å…¥å‘é‡æ•°æ®åº“ chromadb
def store_chroma(docs, embeddings, persist_directory='VectorStore'):
    # ä» docsï¼ˆdocumentï¼‰æ–‡æœ¬æ–‡ä»¶å†™å…¥
    db = Chroma.from_documents(docs, embeddings, persist_directory=persist_directory)
    # æŒä¹…åŒ–ç›®å½•
    db.persist()
    return db
# å¦‚æœæ²¡æœ‰ Vectorstoreï¼Œä¾ embedding åˆ›å»º
if not os.path.exists("Vectorstore"):
    db = store_chroma(documents, embeddings)
else:
    db = Chroma(persist_directory='VectorStore', embedding_function=embeddings)
```

è¿™é‡Œä½¿ç”¨äº† chromadb å¯¹å‘é‡åŒ–çš„æ•°æ®è¿›è¡Œä¿å­˜~

- æ£€ç´¢å™¨ï¼ˆRetrieversï¼‰

```python
retriever = db.as_retriever()
```

è¿™é‡Œç›´æ¥å°† db è½¬åŒ–ä¸ºæ£€ç´¢å™¨ï¼Œä¸€è¡Œå°±æå®šäº†~



#### ï¼ˆ3ï¼‰æ¨¡å—ä¸‰ && å››ï¼šé“¾ Chains && ä»£ç† Agent

Chains ç»å¯¹è¯´å¾—ä¸Šæ˜¯ langchain çš„æ ¸å¿ƒï¼Œä½†æ˜¯å¹¶ä¸å‡†å¤‡èŠ±å¾ˆå¤šç¯‡å¹…æ¥è®²ä»–ã€‚åœ¨å‰ä¸¤ä¸ªæ¨¡å—é‡Œï¼Œæˆ‘ä»¬å·²ç»èƒ½åŠ è½½ä¸Šæ¨¡å‹ã€å­˜å‚¨ä¸Šå‘é‡åŒ–çš„æ•°æ®å¹¶ä¸”å‡†å¤‡å¥½æ£€ç´¢äº†ã€‚ä»¥äººæ¥æ¯”å–»ï¼Œè¿™ä¸ªæ—¶å€™ä½ æ‹¥æœ‰äº†ä¸€ä¸ªå…·æœ‰è¡¨è¾¾èƒ½åŠ›ä¸”å¤§è„‘ä¸­æœ‰ä¸€å®šçŸ¥è¯†ï¼Œå¹¶ä¸”ä½ èƒ½è®©ä»–ä¾æ®çŸ¥è¯†è¿›è¡Œå›ç­”ã€‚ï¼ˆä¸‹é¢æˆ‘çš„ä¾‹å­å’Œè¯´æ³•å¯èƒ½å¹¶ä¸å‡†ç¡®ï¼‰

Chains æ¨¡å—å…è®¸æˆ‘ä»¬å°†ä¹‹å‰çš„äººç»„è£…èµ·æ¥ï¼š

```python
from langchain.chains import RetrievalQA
qa = RetrievalQA.from_chain_type(
    llm=llm,
    # ç»„è£…æ¨¡å¼ï¼Œå¯é€‰ stuff | Refine | Map reduce | Map rerank
    chain_type='stuff',
    retriever=retriever
)
```

å½“ç„¶ä½ ä¹Ÿå¯ä»¥åœ¨è¿™æ¡ Chain ä¸Šå»¶å±•ï¼ŒåŸåˆ™ä¸Šä¸€ä¸ªäººæœ‰ä¸¤ä¸ªå¤§è„‘ã€å››ç§æ£€ç´¢æ–¹å¼ã€å…«ä¸ªè¡¨è¾¾è¯­å¥å¹¶ä¸æ˜¯ä»€ä¹ˆå¥‡æ€ªçš„äº‹ï¼ŒChains æ¨¡å—å°±æ˜¯ä¿è¯è¿™æ¡æµæ°´çº¿èƒ½å¤Ÿæ­£å¸¸æ‰§è¡Œã€‚

è€Œ Agents æ¨¡å—å…è®¸è¿™ä¸ªäººä½¿ç”¨ç‚¹å·¥å…·æ¥å¸®åŠ©æ“ä½œï¼Œæ¯”å¦‚æˆ‘éœ€è¦è®¡ç®— 10000 x 10000ï¼Œæ˜æ˜è®¡ç®—å™¨èƒ½ç®—çš„ä¸œè¥¿è®©æˆ‘ç”¨å¤§è„‘ç®—å²‚ä¸æ˜¯å¤ªæŠ˜ç£¨äº†å—ï¼ˆæˆ‘æƒ³åˆ°äº†ç°åœ¨ GPU å’Œ CPU çš„çˆ±æ¨æƒ…ä»‡ï¼‰ï¼Œå› æ­¤ï¼Œä»£ç†æ¨¡å—é€šè¿‡æä¾›ä»£ç†æ‰§è¡Œå™¨ Agent Executors ç®€åŒ–äº†ä¸€äº›ä¸å¿…è¦çš„è®¡ç®—ï¼Œæˆ–è€…è¯´ï¼Œé€šè¿‡ç»™äºˆä¸€äº›äººâ€èŒä¸šâ€œï¼Œæ¥è®©å¤„ç†æ•ˆæœæ›´åŠ é«˜æ•ˆä¸”å‡†ç¡®ã€‚

å¦‚åŒæœ€è¿‘çœ‹äº†è§£åˆ°çš„ XAgentï¼Œå¤šä¸ª Agent åä½œèƒ½æŠŠæ•ˆç‡æœ€å¤§åŒ–ï¼ˆä»€ä¹ˆèµ›åšå¥´éš¶ï¼‰

ç„¶åæœ€åä»‹ç»ä¸‹ Chains çš„ç±»å‹ï¼š

- Stuff

![](img/langchain/Stuff.png)

stuff æ— ä¼˜åŒ–ï¼Œå°±æ˜¯ä¸€æ¡ç›´é“¾ã€‚

eg. å‡å¦‚ token åªæœ‰ 8000ï¼Œè¾“å…¥ 10000 å°±ä¼š oom

- Refine

![](img/langchain/Refine.png)

refine å¾ªç¯ï¼ˆloopï¼‰è°ƒç”¨ï¼Œå¯¹æ–‡æ¡£å†…å®¹åˆ†ç‰‡ï¼Œå¹¶å°†ä¸Šä¸€è½®çš„ç»“æœä½œä¸ºä¸‹ä¸€è½®çš„è¾“å…¥æ”¾å…¥ã€‚

eg. token 8000ï¼Œåˆ†ç‰‡å‡å¦‚ 2000ï¼Œå°±ä¼šå°† 10000 çš„æ–‡æœ¬è½¬æ¢æˆ 2000 + ä¸Šä¸€è½®å¾ªç¯ç»“æœè¿›è¡Œè¾“å…¥

- Map reduce

è¿™ä¸ªå°±ä¸ç”¨ä»‹ç»äº†å§ï¼Œå­¦å¤§æ•°æ®éƒ½å†™çƒ‚äº†~æˆ‘å…¶ä»–æ–‡ç« è‡³å°‘ä»‹ç»è¿‡ 3 é MapReduce äº† emmmm

- Map rerankï¼ˆæ²¡äº†è§£ï¼Œæœ‰æœºä¼šå†è¡¥ï¼‰



#### ï¼ˆ4ï¼‰æ¨¡å—äº” && å…­ è®°å¿†å­˜å‚¨ï¼ˆMemoryï¼‰ &&  æç¤ºå·¥ç¨‹ï¼ˆPromptsï¼‰

Memory æ¨¡å—æ²¡ç”¨è¿‡ï¼ŒåŸºæœ¬æ˜¯å¯¹å†…å­˜ã€å‘é‡ç©ºé—´ã€çŸ¥è¯†å›¾è°±ç­‰è¿›è¡Œæ“ä½œï¼Œç›®å‰æˆ‘è¿˜æ²¡ç”¨è¿‡å°±ä¸ç­é—¨å¼„æ–§äº†ã€‚

Prompts æ¨¡å—å¯èƒ½ä¼šæ˜¯ç”¨å¾—æœ€å¤šçš„æ¨¡å—ï¼Œä¹Ÿæ˜¯â€ä¼ªâ€œè°ƒä¼˜ã€ç³Šå¼„ä¸Šå¸çš„ä¸€æŠŠå¥½æ‰‹ï¼šlangchain çš„é»˜è®¤æç¤ºè¯éƒ½æ˜¯è‹±æ–‡çš„ï¼Œå³ä½¿ä½ ç»™ä»–çš„éƒ½æ˜¯ä¸­æ–‡è¯­æ–™ï¼Œä½†æ˜¯å¯èƒ½å› ä¸ºæç¤ºè¯æ˜¯è‹±æ–‡çš„å¯¼è‡´è¾“å‡ºæ˜¯è‹±æ–‡ or å››ä¸åƒã€‚å› æ­¤ï¼Œå¯¹äºè¾“å‡ºè¿›è¡Œè§„èŒƒçš„ç¬¬ä¸€æ­¥å°±æ˜¯ä½¿ç”¨è‡ªå·±çš„æç¤ºè¯ã€‚

```python
from langchain.prompts import PromptTemplate
prompt_template = """æ€»ç»“è¿™æ®µæ–°é—»çš„å†…å®¹ï¼š
    "{text}"
    æ€»ç»“:"""
# å°†è¾“å…¥å†…å®¹å¡«å……è¿› prompt æ¨¡æ¿
chinese_prompt = PromptTemplate(template=prompt_template, input_variables=["text"])
# prompt ä¹Ÿæ˜¯ chain play çš„ä¸€ç¯å•Š
chain = load_summarize_chain(llm, prompt=chinese_prompt)
```

å¯è§ï¼Œprompt æ“ä½œå…¶å®æ˜¯é’ˆå¯¹æ‰¹é‡åŒ–å¤„ç†ç­‰æ“ä½œçš„ä¸€ä¸ªç®€åŒ–æ­¥éª¤ï¼Œä¾‹å¦‚ä½ ä½¿ç”¨çˆ¬è™«çš„æ—¶å€™å°±èƒ½å¾ˆå¥½çš„æ§åˆ¶è¾“å‡ºè€Œä¸å¿…è¿‡äºæ‹…å¿ƒå†…å®¹çš„å·®å¼‚æ€§ã€‚å½“ç„¶ä¹Ÿæœ‰ä¸“é—¨å¯¹è¾“å‡ºæ ¼å¼è¿›è¡Œè§„çº¦çš„ï¼Œæ¯”å¦‚ï¼š

```python
from langchain.output_parsers import PydanticOutputParser
template = """\
        æˆ‘å°†ç»™ä½ ä¸€æ®µæ–°é—»çš„æ¦‚æ‹¬ï¼Œè¯·æŒ‰ç…§è¦æ±‚æŠŠè¿™æ®µæ–°é—»æ”¹å†™æˆéƒ­å¾·çº²å’Œäºè°¦çš„å¯¹å£ç›¸å£°å‰§æœ¬ã€‚
    
        æ–°é—»: "{æ–°é—»}"
        è¦æ±‚: "{è¦æ±‚}"
        {output_instructions}
    """
parser = PydanticOutputParser(pydantic_object=XiangSheng)
prompt = PromptTemplate(
    template=template,
    input_variables=["æ–°é—»", "è¦æ±‚"],
    partial_variables={"output_instructions": parser.get_format_instructions()}
)
class XiangSheng(BaseModel):
    script: List[Line] = Field(description="ä¸€æ®µç›¸å£°çš„å°è¯å‰§æœ¬")
```

æ ¼å¼çš„è§„çº¦ä¸»è¦è¿˜æ˜¯ç”¨åœ¨åæœŸçš„æ•°æ®å¤„ç†ä¸Šï¼Œå› æ­¤ parser è¿™ä¸ªæ“ä½œå®Œå…¨å¯ä»¥çœ‹ä½œ prompt çš„ promptï¼Œä¸€ä¸ªæ˜¯ä»è¯­è¨€å±‚é¢ä¸Šçš„çº¦æŸï¼Œä¸€ä¸ªæ˜¯ä»ä»£ç å±‚é¢ä¸Šçš„çº¦æŸï¼Œæœ¬è´¨ä¸Šå¹¶æ— ç‰¹åˆ«å¤§çš„åŒºåˆ«ã€‚

------



## 5 æ€»ç»“

åˆ°è¿™é‡Œï¼Œå…¶å®çœ‹ä¼¼å¥½åƒå•¥éƒ½è®²äº†ï¼Œä½†æ˜¯åˆå¥½åƒå•¥éƒ½æ²¡è®²ã€‚ä¸è¿‡æŠŠä¸Šé¢æ¨¡å—ä¸­ä»‹ç»çš„ä»£ç æ‹¼å‡‘èµ·æ¥ï¼Œä½ å·²ç»èƒ½å¤Ÿå®ç°ä¸€ä¸ªâ€æœ¬åœ°çŸ¥è¯†åº“é—®ç­”â€œçš„åŠŸèƒ½ï¼Œè‡ªå·±åœ¨å†™å‡ ä¸ª api è°ƒç”¨ï¼Œå·²ç»é¥é¥é¢†å…ˆäºè¿‡å»åƒç¯‡ä¸€å¾‹çš„ç³»ç»Ÿäº†ï¼ˆç„¶è€Œå®é™…ä¸Šä»£ç åªæœ‰ 60 è¡Œä¸åˆ°ï¼‰ã€‚

è¿™å‡ ä¸ªå°å®è·µçš„ä»£ç ä¼šåœ¨ä¹‹åçš„ã€ŠLangChain å®è·µã€‹ä¸­ï¼Œå…¶å®ä¹Ÿæ²¡å•¥ï¼Œéƒ½æ˜¯ç…§ç€æˆ‘å‰é¢æåˆ°çš„å‡ ä¸ªéå¸¸æ£’çš„ B ç«™æ•™å­¦æ“ä½œçš„ã€‚ä¸è¿‡ä¸ºäº†æ–¹ä¾¿ä¸æƒ³çœ‹è¯¾ä»¥åŠ debug çš„åŒå­¦æ“ä½œï¼Œåˆ°æ—¶å€™ä¼šæŠŠæ³¨é‡Šæ‰“å¥½å†å‘å‡ºæ¥ï¼ˆå¦‚æœä¸æƒ³ debug å»ºè®®è¿˜æ˜¯åˆ«å­¦äº†ï¼Œæ–°æŠ€æœ¯è¦çš„å°±æ˜¯ä¸åœçš„ debugï¼‰

æ€»ä¹‹ï¼Œlangchain å…¶å®å°±æ˜¯ä¸€ä¸ªäººç±»ä¸ LLMs äº¤äº’çš„ä¸­é—´ä»¶ï¼Œä¸è¿‡å®ƒçš„å¯ç©æ€§å¾ˆè¶³ï¼Œæ”¯æŒåŒ…æ‹¬ B ç«™è§†é¢‘ç­‰è¾“å…¥æºçš„æ•°æ®è¾“å…¥ï¼ˆå› æ­¤ï¼Œæˆ‘æœ‰ç†ç”±æ€€ç–‘æœ€è¿‘ B ç«™çš„ä¸€å¤§å † AI è§†é¢‘åŠ©æ‰‹å¤šå°‘éƒ½ä½¿ç”¨äº† langchainï¼‰ã€‚å·¥å…·æƒ³è¦ç†Ÿç»ƒåªèƒ½æ˜¯å¤šå®è·µï¼Œä¸è¦å› ä¸ºç¯å¢ƒçš„é™åˆ¶è€Œåœä¸‹è„šæ­¥~

æœ¬å®è·µåœ¨ P106-100 6G â‰ˆ 1060 6G å®Œæˆ T_Tï¼Œå•¥æ—¶å€™æœ‰å¯Œå©†æ”¯æ´ä¸€å— 4090 ç‚¼ä¸¹å•Š~