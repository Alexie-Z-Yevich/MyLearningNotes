# 深度学习的音乐创作综述

Carlos Hernandez-Olivan

Jose R. Beltran

Department of Engineering and Communications, Calle María de Luna, Universidad de Zaragoza

> **观后简言：**
>
> 

#### 摘要

产生一件复杂的艺术作品，如音乐作品，需要表现出真正的创造力，这取决于与音乐语言层次相关的各种因素。音乐生成一直面临着算法方法，最近还面临着在计算机视觉等其他领域使用的深度学习模型。在本文中，我们希望将基于人工智能的音乐创作模型与人类音乐创作和创造力过程之间的现有关系放在上下文中。我们概述了最近的音乐创作深度学习模型，并从理论角度将这些模型与音乐创作过程进行了比较。我们试图通过分析当前深度学习模型生成具有创造力的音乐的能力，或者人工智能和人类作曲过程之间的相似性等，来回答这项任务中一些最相关的开放性问题。

**关键词：**音乐生成、深度学习、机器学习、神经网络



#### 1 简介

音乐通常被定义为一系列音高或节奏，或两者兼有，在某些特定的模式中。音乐创作（或生成）是创作或创作一首新音乐的过程。音乐创作术语也可以指原创音乐作品。音乐创作需要创造力，这是人类理解和创造一种语言中无穷句子的独特能力，其中大多数句子以前从未遇到或说过。这是在设计或提出基于人工智能的音乐创作算法时需要考虑的一个非常重要的方面。

更具体地说，音乐创作是音乐信息检索领域的一个重要课题。它包括旋律生成、多音轨或多乐器生成、风格转换或协调等子任务。本文将从近年来基于 AI 和 DL 的大量技术的角度来涵盖这些方面。

##### 1.1 从算法合成到深度学习

自 20 世纪 80 年代以来，人们对计算机音乐创作的兴趣从未停止过增长。一些实验出现在 20 世纪 80 年代初，如 David Cope 在 1983 年至 1989 年的音乐智能实验或 Iannis Xenakis 的 Analogiques A 和 B。2000 年代后期，David Cope 还提出了将马尔可夫链与语法相结合用于自动音乐创作，并诞生了其他相关作品，如 Koening 的 Project1（PR1）。这些技术可以归入算法音乐创作领域，这是一种通过可形式化方法进行创作的方式。这种类型的组成是基于一个受控过程，该过程基于必须按照固定顺序遵循的数学指令。算法组合中有几种方法，如马尔可夫模型、生成语法、细胞自动机、遗传算法、过渡网络或 Caos 理论。有时，这些技术和其他概率方法与深度神经网络相结合，以调节它们或帮助它们更好地建模音乐，DeepBach 就是这样。这些模型可以生成和协调不同风格的旋律，但缺乏可推广性。与基于 Depp 学习的模型相比，这些模型的能力和必须手工完成的基于规则的定义使这些方法的功能和可推广性较差。

从 20 世纪 80 年代到 21 世纪初，第一批尝试用神经网络建模音乐的作品诞生了。近年来，随着深度学习（DL）的发展，许多研究试图用深度神经网络（NN）对音乐进行建模。用于音乐生成的 DL 模型通常使用 NN 架构，该架构已被证明在其他领域（如计算机视觉或自然语言处理（NLP））中表现良好。在这些领域中也可以使用预先训练的模型，用于音乐生成。这被称为迁移学习。本文稍后将介绍一些神经网络技术和体系结构。今天的音乐创作采用了来自大规模 NLP 应用程序的输入表示和 NNs 架构，例如基于 Transformer 的模型，它们在这项任务中表现出了非常好的性能。这是因为音乐可以被理解为一种语言，在这种语言中，每种风格或音乐流派都有自己的规则。

##### 1.2 用于深度学习音乐创作的神经网络架构

首先，我们将概述迄今为止在音乐创作任务中提供最佳结果的最广泛使用的神经网络架构。音乐创作任务中最常用的神经网络架构是生成模型，如变分自动机（VAE）或生成对抗网络（GAN），以及基于 NLP 的模型，如长短期记忆（LSTM）或 Transformers。以下是这些型号的概述。

###### 1.2.1 可变自动编码器（VAEs）

原始 VAE 模型使用编码器-解码器架构，通过重建输入来产生潜在空间（见图 1a）。潜在空间是压缩数据的多维空间，其中最相似的元素彼此最接近。在 VAE 中，编码器近似后验，解码器参数化似然。后验近似和似然近似分别由编码器和解码器的具有 λ 和 θ 参数的 NN 进行参数化。后验推理是通过最小化编码器或近似后验之间的 Kullback-Leiber（KL）分歧来完成的，而真正的后验推理则是通过最大化证据下界（ELBO）来完成的。

梯度是用所谓的重新参数化技巧计算的。原始 VAE 模型有一些变化，如 β-VAE，它在重建损失中添加了惩罚项 β，以改善潜在空间分布。在图 1a 中，我们展示了通用 VAE 架构。基于 VAE 的音乐创作 DL 模型的一个例子是 MusicVAE，我们将在本文的下一节中对此进行描述。

![图 1a](img/1a.png)

###### 1.2.2 生成对抗性网络（GANs）

GANs 是由两个 NN 组成的生成模型：生成器 G 和鉴别器 D。生成器学习输入数据上的分布 p~g~。进行训练是为了让鉴别器最大限度地为训练样本和生成器生成的样本分配正确标签的概率。这种训练思想可以理解为 D 和 G 遵循 Goodfellow 等人所描述的两人极小极大博弈。在图 1b 中，我们展示了通用 GAN 架构。

生成器和判别器可以由不同的 NN 层形成，如多层感知器（MLP）、LSTM 或卷积神经网络（CNN）。

![图 1b](img/1b.png)

###### 1.2.3 Transformers

Transformers 目前正在 NLP 应用中广泛使用，因为它们不仅在 NLP 中表现良好，而且在计算机视觉模型中也表现良好。Transformers 可以用作自回归模型，如 LSTM，这允许它们用于生成任务。Transformers 背后的基本思想是注意力机制。Vaswani 等人提出的原始注意力机制有几种变体，已用于音乐创作任务。注意力层和前馈层的结合导致了 Transformer 的编码器和解码器的形成，这与同样由编码器和解码器组成的纯 AutoEncoder 模型不同。

Transformers 使用令牌进行训练，令牌是输入的结构化表示。在图 1c 中，我们展示了通用变压器架构。

![图 1c](img/1c.png)

##### 1.3 深度学习在音乐创作中的挑战