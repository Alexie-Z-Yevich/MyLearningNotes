# 深度学习的音乐创作综述

Carlos Hernandez-Olivan

Jose R. Beltran

Department of Engineering and Communications, Calle María de Luna, Universidad de Zaragoza

> **观后简言：**
>
> 

#### 摘要

产生一件复杂的艺术作品，如音乐作品，需要表现出真正的创造力，这取决于与音乐语言层次相关的各种因素。音乐生成一直面临着算法方法，最近还面临着在计算机视觉等其他领域使用的深度学习模型。在本文中，我们希望将基于人工智能的音乐创作模型与人类音乐创作和创造力过程之间的现有关系放在上下文中。我们概述了最近的音乐创作深度学习模型，并从理论角度将这些模型与音乐创作过程进行了比较。我们试图通过分析当前深度学习模型生成具有创造力的音乐的能力，或者人工智能和人类作曲过程之间的相似性等，来回答这项任务中一些最相关的开放性问题。

**关键词：**音乐生成、深度学习、机器学习、神经网络



#### 1 简介

音乐通常被定义为一系列音高或节奏，或两者兼有，在某些特定的模式中。音乐创作（或生成）是创作或创作一首新音乐的过程。音乐创作术语也可以指原创音乐作品。音乐创作需要创造力，这是人类理解和创造一种语言中无穷句子的独特能力，其中大多数句子以前从未遇到或说过。这是在设计或提出基于人工智能的音乐创作算法时需要考虑的一个非常重要的方面。

更具体地说，音乐创作是音乐信息检索领域的一个重要课题。它包括旋律生成、多音轨或多乐器生成、风格转换或协调等子任务。本文将从近年来基于 AI 和 DL 的大量技术的角度来涵盖这些方面。

##### 1.1 从算法合成到深度学习

自 20 世纪 80 年代以来，人们对计算机音乐创作的兴趣从未停止过增长。一些实验出现在 20 世纪 80 年代初，如 David Cope 在 1983 年至 1989 年的音乐智能实验或 Iannis Xenakis 的 Analogiques A 和 B。2000 年代后期，David Cope 还提出了将马尔可夫链与语法相结合用于自动音乐创作，并诞生了其他相关作品，如 Koening 的 Project1（PR1）。这些技术可以归入算法音乐创作领域，这是一种通过可形式化方法进行创作的方式。这种类型的组成是基于一个受控过程，该过程基于必须按照固定顺序遵循的数学指令。算法组合中有几种方法，如马尔可夫模型、生成语法、细胞自动机、遗传算法、过渡网络或 Caos 理论。有时，这些技术和其他概率方法与深度神经网络相结合，以调节它们或帮助它们更好地建模音乐，DeepBach 就是这样。这些模型可以生成和协调不同风格的旋律，但缺乏可推广性。与基于 Depp 学习的模型相比，这些模型的能力和必须手工完成的基于规则的定义使这些方法的功能和可推广性较差。

从 20 世纪 80 年代到 21 世纪初，第一批尝试用神经网络建模音乐的作品诞生了。近年来，随着深度学习（DL）的发展，许多研究试图用深度神经网络（NN）对音乐进行建模。用于音乐生成的 DL 模型通常使用 NN 架构，该架构已被证明在其他领域（如计算机视觉或自然语言处理（NLP））中表现良好。在这些领域中也可以使用预先训练的模型，用于音乐生成。这被称为迁移学习。本文稍后将介绍一些神经网络技术和体系结构。今天的音乐创作采用了来自大规模 NLP 应用程序的输入表示和 NNs 架构，例如基于 Transformer 的模型，它们在这项任务中表现出了非常好的性能。这是因为音乐可以被理解为一种语言，在这种语言中，每种风格或音乐流派都有自己的规则。

##### 1.2 用于深度学习音乐创作的神经网络架构

首先，我们将概述迄今为止在音乐创作任务中提供最佳结果的最广泛使用的神经网络架构。音乐创作任务中最常用的神经网络架构是生成模型，如变分自动机（VAE）或生成对抗网络（GAN），以及基于 NLP 的模型，如长短期记忆（LSTM）或 Transformers。以下是这些型号的概述。

###### 1.2.1 可变自动编码器（VAEs）

原始 VAE 模型使用编码器-解码器架构，通过重建输入来产生潜在空间（见图 1a）。潜在空间是压缩数据的多维空间，其中最相似的元素彼此最接近。在 VAE 中，编码器近似后验，解码器参数化似然。后验近似和似然近似分别由编码器和解码器的具有 λ 和 θ 参数的 NN 进行参数化。后验推理是通过最小化编码器或近似后验之间的 Kullback-Leiber（KL）分歧来完成的，而真正的后验推理则是通过最大化证据下界（ELBO）来完成的。

梯度是用所谓的重新参数化技巧计算的。原始 VAE 模型有一些变化，如 β-VAE，它在重建损失中添加了惩罚项 β，以改善潜在空间分布。在图 1a 中，我们展示了通用 VAE 架构。基于 VAE 的音乐创作 DL 模型的一个例子是 MusicVAE，我们将在本文的下一节中对此进行描述。

![图 1a](img/1a.png)

###### 1.2.2 生成对抗性网络（GANs）

GANs 是由两个 NN 组成的生成模型：生成器 G 和鉴别器 D。生成器学习输入数据上的分布 p~g~。进行训练是为了让鉴别器最大限度地为训练样本和生成器生成的样本分配正确标签的概率。这种训练思想可以理解为 D 和 G 遵循 Goodfellow 等人所描述的两人极小极大博弈。在图 1b 中，我们展示了通用 GAN 架构。

生成器和判别器可以由不同的 NN 层形成，如多层感知器（MLP）、LSTM 或卷积神经网络（CNN）。

![图 1b](img/1b.png)

###### 1.2.3 Transformers

Transformers 目前正在 NLP 应用中广泛使用，因为它们不仅在 NLP 中表现良好，而且在计算机视觉模型中也表现良好。Transformers 可以用作自回归模型，如 LSTM，这允许它们用于生成任务。Transformers 背后的基本思想是注意力机制。Vaswani 等人提出的原始注意力机制有几种变体，已用于音乐创作任务。注意力层和前馈层的结合导致了 Transformer 的编码器和解码器的形成，这与同样由编码器和解码器组成的纯 AutoEncoder 模型不同。

Transformers 使用令牌进行训练，令牌是输入的结构化表示。在图 1c 中，我们展示了通用变压器架构。

![图 1c](img/1c.png)

##### 1.3 深度学习在音乐创作中的挑战

在使用 DL 的音乐创作中，从挑战的角度来看，有不同的观点，这让我们提出了与该领域中使用的输入表示和 DL 模型、实际最先进方法的输出质量或研究人员测量生成音乐质量的方式有关的问题。在这篇综述中，我们问自己以下涉及合成过程和输出的问题：当前的 DL 能够产生具有一定创造力的音乐的模型吗？使用 DL 进行音乐创作的最佳 NN 架构是什么？端到端的方法能生成完整的结构化音乐片段吗？带有 DL 的作曲作品只是对输入的模仿吗？还是 NN 可以生成训练数据中不存在的风格的新音乐？神经网络应该像人类一样遵循同样的逻辑和过程来创作音乐吗？用于音乐生成的 DL 模型需要多少数据？目前的评估方法是否足以比较和衡量创作音乐的创造力？

为了回答这些问题，我们从获得最终作品和 DL 模型输出的过程的角度来研究音乐创作或生成，即人类创作过程和深度学习的音乐生成过程之间的比较，以及生成的音乐所呈现的艺术和创作特征。我们还分析了最近最先进的深度学习音乐创作模型，以显示这些模型提供的结果（主题、完整的作品…）。分析的另一个重要方面是这些模型用于生成音乐的输入表示，以了解这些表示是否适合作曲。这让我们对如何改进这些模型有了一些见解，如果这些神经网络架构足够强大，能够以一定的创造力创作新音乐，以及深度学习音乐创作的方向和未来工作。

##### 1.4 论文结构

在这篇综述中，我们从作曲过程和生成输出的类型来分析音乐作曲任务，我们不包括作品或合成任务。本文的结构如下。第 2 节介绍了音乐创作的一般过程和音乐创作的基本原则。在第 3 节中，我们从旋律作曲的角度概述了最先进的方法，并描述了已测试用于创作结构化音乐的 DL 模型。在第 4 节中，我们描述了生成多音轨或多乐器音乐的 DL 模型，即为多个乐器制作的音乐。在第 5 节中，我们展示了通常用于评估音乐生成模型输出的不同方法和指标。在第 6 节中，我们通过分析我们在第 3 节和第 4 节中描述的模型，描述了音乐生成中仍然存在的悬而未决的问题。最后，在第 7 节中，我们介绍了未来的工作和研究中仍然存在的挑战。



#### 2 音乐创作过程

与书面语言一样，音乐创作过程是一个复杂的过程，取决于大量的决策。在音乐领域，这个过程取决于我们所使用的音乐风格。例如，在古典音乐中，从一个或两个小节的一个小单元开始，称为主题，并将其发展为旋律或音乐短语，这是非常常见的。在流行音乐或爵士乐等风格中，更常见的是采用和弦进行，并在其前面创作或即兴创作旋律，当一个作曲家开始一首音乐时，它背后有一些基本的旋律或和声思想。从古典音乐的角度来看，这个思想（或主题）是由作曲家发展起来的，以构建遵循特定和声进程的旋律或短语，然后这些短语被分段构建。每一节都有自己的目的，因此可以用不同的键书写，其短语通常遵循与其他节不同的和声进行。通常，作品有旋律部分和伴奏部分。一首音乐的旋律部分可以由不同的乐器演奏，这些乐器的频率范围可能相似，也可能不相似，和声部分给这首音乐一种深刻而结构化的感觉。不一定在同一频率范围内的乐器与乐器和编排技术相结合（见第 3.2 节）。这些元素在音乐创作中至关重要，也是定义音乐风格或流派的重要关键。音乐，有两个维度，时间维度和和声维度。时间维度由音符持续时间或节奏表示，这是该轴中的最低级别。在此维度中，注释可以按称为条形的单位进行分组或测量，条形是有序的注释组。另一个维度，和声，与音符值或音高有关。如果我们考虑一个图像，时间维度是横轴，和弦维度是纵轴。和声也有时间上的演变，但这并没有体现在乐谱中。有一种非常常见的基于软件的音乐表示，称为钢琴卷，遵循这种逻辑。

音乐时间维度是以音符为低级单位构建的，这些音符被分组为小节，形成（主题）。在时间高级维度中，我们可以找到由持续八小节或更多小节的短语组成的部分（这取决于风格和作曲家）。和声维度的最低层次是音符层次，然后不同乐器演奏的音符的叠加给了我们和弦。和弦序列被称为和弦进程，与作曲相关，它们在时间维度上也有相关性。话虽如此，我们可以将音乐视为一种复杂的语言模式，由短期和长期关系组成。这些关系在两个维度上延伸，与音乐结构相关的时间维度和与音符或音高和和弦相关的和声维度，即和声。

从符号音乐生成和分析的角度来看，基于 Walton 的思想，音乐的基本原理或元素是（见图 2a）：

![图 2a 总体音乐创作方案](img/2a.png)

- 和声。正是音符的叠加形成了和弦，构成了和弦的进程。音符级别可以被认为是和声的最低级别，其次是和弦级别。最高级别可以被认为是通常属于某个关键的进展级别。
- 音乐形式或结构。它是音乐呈现的高级结构，与时间维度有关。音乐作品中最小的部分是在音乐短语中发展起来的主题，音乐短语的组合形成了一个部分。音乐中的小节是根据音乐风格排序的，例如一些流行歌曲的介绍诗合唱诗（也称为 ABCBA）或奏鸣曲的阐述发展重述或 ABA。不同规模和模式的部分的串联为我们提供了整个构图。
- 旋律和质感。音乐术语中的质感是指为了形成音乐作品，必须在作品中结合旋律、节奏和和声的内容。音乐可以是单声道的，也可以是复调的，这取决于在同一时间段播放的音符，同音的或异音的取决于旋律，对有伴奏或没有伴奏进行区分。
- 乐器和编排。这些音乐技巧考虑了一首音乐作品中乐器或曲目的数量。乐器是指组成一首音乐作品的乐器的组合，而编排是指为组成一首确定的音乐作品的不同乐器分配旋律和伴奏。在录音或基于软件的音乐表现中，乐器被组织为曲目。每首曲目都包含在单个乐器上演奏的音符集。因此，我们可以将一首有多首乐器的乐曲称为多音轨，这是指包含两首或多首曲目的信息，其中每首曲目由一首乐器演奏。每个音轨可以包含一个音符或多个同时发出声音的音符，从而分别产生单声道音轨和复调音轨。

音乐类别之间是相关的。和声与结构有关，因为一个小节通常以相同的音阶和模式演奏。小节之间有抑扬顿挫的节奏，也可以有改变乐曲规模的调调。质地和乐器与音色特征有关，它们之间的关系是基于这样一个事实，即并非所有的乐器都能演奏相同的旋律。一个例子是，当我们有一首带有大量装饰元素的旋律，而这些元素无法用确定的乐器家族演奏（因为每种乐器可能有的技巧或设计的原因）。

另一个重要的音乐属性是动态，但它们与表演有关，而不是与作品本身有关，因此我们在这篇综述中不涉及它们。在图 2b 中，我们展示了我们在这篇综述中涵盖的音乐创作过程的各个方面，并描述了类别之间的关系和论文中讨论每个主题的部分。

![图 2b 贝多芬第五交响曲开头的音乐级别或类别的例子](img/2b.png)



#### 3 旋律生成

旋律是一系列具有一定节奏的音符，以一种美学的方式排列。旋律可以是单声道的，也可以是复调的。单音是指在一个时间步长内只演奏一个音符的旋律，而在复调旋律中，在同一时间步长内演奏多个音符。旋律生成是音乐创作的重要组成部分，并且已经尝试了算法合成和包括生成模型（如 VAE 或 GAN）、用于自回归任务（如 LSTM）的递归神经网络（RNN）的几种 NN 架构，神经自回归分散估计（NADE）或自然语言处理中使用的当前模型，如 Transformers。在图 3 中，我们展示了具有旋律生成模型的类似输出的乐谱的音乐基本原理的方案。

![图 3 旋律生成模型的类输出乐谱的方案](img/3.png)

##### 3.1 旋律生成的深度学习模型：从主题到旋律短语