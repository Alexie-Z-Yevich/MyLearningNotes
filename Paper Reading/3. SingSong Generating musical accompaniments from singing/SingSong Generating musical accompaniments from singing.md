# SingSong：从 SingSong 中产生音乐伴奏

**Chris Donahue，Antoine Caillon，Adam Roberts，Ethan Manilow，Philippe Esling，Andrea Agostinelli，Mauro Verzetti，Ian Simon，Olivier Pietquin，Neil Zeghidour，Jesse Engel**

> **观后简言：**
>
> 



#### 摘要

我们介绍了 SingSong，这是一个通过人声进行音乐生成的系统，有可能为音乐家和非音乐家提供一种直观的新方式来创作具有自己声音特色的音乐。为了实现这一点，我们在音乐源分离和音频生成方面的最新发展的基础上进行了研究。具体来说，我们将最先进的源分离算法应用于大型音乐音频语料库，以产生对齐的人声和乐器源。然后，我们将 AudioLM（Borsos等人，2022）——一种最先进的无条件音频生成方法——调整为适用于有条件的“音频到音频”生成任务，并在源分离（声乐、器乐）对上对其进行训练。在与相同声音输入的成对比较中，与来自强检索基线的相比，听众表示 SingSong 生成的音乐伴奏有显著的提高。



#### 1. 简介

唱歌是参与音乐的最直观的途径之一，无论是音乐家还是非音乐家都可以使用。尽管跟着现有音乐唱歌是一种常见的活动，但唱歌也可能构成音乐生成系统的直观控制机制，可能会让任何会唱歌的人以一种有趣和参与的方式创作音乐。

在这项工作中，我们提出了 SingSong（图 1），这是一个能够生成器乐音频来同步伴随输入人声音频的系统，即输出的乐器可以与输入人声天然混合，以创建具有输入特征的连贯音乐。SingSong 利用音乐技术的两个关键领域的改进：源分离和音频的生成建模。我们使用 Kim 等人的现成源分离算法。（2021）将大量不同的音乐语料库（1M 首曲目）分离为对齐的人声和乐器源对，构成我们任务的并行数据。然后，我们改编了 AudioLM（Bor-sos 等人，2022）——一个涉及中间表示层次的音频无条件生成模型——适用于给定人声的乐器的条件“音频到音频”生成建模，并以监督的方式在源分离数据上对其进行训练。

![图 1 SingSong 生成器乐来伴随输入人声，从而允许用户创建以自己的声音为特色的音乐。（左）我们通过将现成的源分离算法应用于大型音乐音频语料库来为这项任务制造大量的合成数据，我们使用该算法来训练给定人声的乐器的生成模型。（右）在推断的时候，SingSong 从用户那里获取人声，并输出一个乐器来伴奏这些人声，这些乐器可以天然的与输入混合，创造出连贯的音乐
*请注意，在训练过程中，我们计算离散音频特征的损失，而不是波形（第 3.3 节）](img/1.png)

这项工作中的一个关键挑战是建立一个系统，该系统能够从训练期间观察到的源分离的人声输入推广到现实世界中的孤立人声，人们可以从参与该系统的用户那里预期。初步实验得出的模型强烈倾向于从源分离人声中几乎听不见的伪影（conceal artifacts）中重建乐器——当输入孤立人声时，这些模型产生了荒谬的输出。为了提高泛化能力，我们为输入人声提出了两种特征化策略：（1）向人声输入添加噪声以隐藏伪影，以及（2）仅使用 AudioLM 中最粗糙的中间表示作为条件输入。在感知相关的指标上，与默认的 AudioLM 特征化相比，这些特征化共同将孤立视频的性能提高了 55%。

在一项配对研究中，听众被呈现出两种人声相同的声乐器乐混音，与强检索基线相比，听众对 SingSong 的器乐表现出显著的偏好。该基线使用 vocals 的音乐特征（节拍和键）作为查询，以检索具有相似特征的人类创作的器乐。与这个检索基线的乐曲相比，66%的时间听众更喜欢 SingSong 的乐曲。此外，即使与现实乐器相比，听众也有 34% 的时间更喜欢 SingSong 的乐曲。

总之，我们的主要贡献是：

- 我们是第一个使用生成建模为人声输入创建连贯乐器伴奏的公司。
- 我们是第一个提出使用源分离来创建音频到音频伴奏的训练数据的公司。
- 我们采用最先进的无条件音频生成模型进行有条件的音频到音频建模。



#### 2. 相关工作

